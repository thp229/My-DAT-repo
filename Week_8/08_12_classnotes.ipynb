{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train = pd.read_csv(\"/Users/theodoreplotkin/desktop/postmalone/GA_Data_Science/DAT-06-24/class material/Unit 3/data/titanic/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"/Users/theodoreplotkin/desktop/postmalone/GA_Data_Science/DAT-06-24/class material/Unit 3/data/titanic/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#EDA\n",
    "import seaborn as sns\n",
    "\n",
    "sns.catplot(x = 'Sex', y = 'Survived', kind = \"bar\", data = train)\n",
    "#baseline model is that if you just predict based on sex, \n",
    "#you have a 75% chance of getting it right if you say woman\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAFgCAYAAACFYaNMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAFFNJREFUeJzt3X+w3Xdd5/HnKzdmkVKXBa4TpkkxQkALVjpew87UQcTWDetM4yw/TK1KZ5AMMwbYxRLD/shilNnZ4MAoxpW4dkHGEmvrrFcnNqNQflhtTYBQSGLcbFrITbhyQym0bsc27Xv/uCfs2ctN7ml7v/dzcs/zMXMn9/s9n3vu+86defbb7z3n+01VIUlaeitaDyBJo8oAS1IjBliSGjHAktSIAZakRgywJDVigCWpEQMsSY0YYElqZGXrAZ6sjRs31h133NF6DEm6kAyy6KI7Aj5z5kzrESRpUVx0AZak5cIAS1IjBliSGjHAktSIAZakRjoNcJKNSY4lOZ5k+zyPvz/Jod7H3yd5sMt5JGmYdPY64CRjwG7gWmAKOJBksqqOnFtTVf+ub/1bgau6mkeShk2XR8AbgONVdaKqHgX2ApsusP564KMdziNJQ6XLAF8GnOzbnurt+zZJXgCsAz5+nse3JDmY5ODMzMyiDypJLXQZ4Pneine+O4BuBm6rqsfne7Cq9lTVRFVNjI+PL9qAktRSlwGeAtb2ba8BTp9n7WY8/SBpxHR5MZ4DwPok64BTzEb2Z+YuSvIS4F8Af9PhLENl27ZtTE9Ps3r1anbt2tV6HEmNdBbgqjqbZCuwHxgDbq6qw0l2AgerarK39Hpgb1Wd7/TEsjM9Pc2pU6dajyGpsU4vR1lV+4B9c/btmLP97i5nkKRh5TvhJKkRAyxJjRhgSWrEAEtSIwZYkhoxwJLUiAGWpEYMsCQ1YoAlqREDLEmNGGBJasQAS1IjBliSGjHAktSIAZakRgywJDVigCWpEQMsSY0YYElqxABLUiMGWJIaMcCS1IgBlqRGDLAkNbKy9QBd+aF3/n7rEc7r0jMPMQZ8+cxDQznnZ977861HkEaCR8CS1IgBlqRGDLAkNWKAJakRAyxJjRhgSWrEAEtSIwZYkhrpNMBJNiY5luR4ku3nWfOGJEeSHE5yS5fzSNIw6eydcEnGgN3AtcAUcCDJZFUd6VuzHngXcHVVfT3Jd3c1jyQNmy6PgDcAx6vqRFU9CuwFNs1Z82Zgd1V9HaCqvtrhPJI0VLoM8GXAyb7tqd6+fi8GXpzkriR3J9k43xMl2ZLkYJKDMzMzHY0rSUurywBnnn01Z3slsB54FXA98N+TPPvbvqhqT1VNVNXE+Pj4og8qSS10GeApYG3f9hrg9Dxr/qSqHquq+4BjzAZZkpa9LgN8AFifZF2SVcBmYHLOmv8J/BhAkucxe0riRIczSdLQ6CzAVXUW2ArsB44Ct1bV4SQ7k1zXW7Yf+FqSI8CdwDur6mtdzSRJw6TTC7JX1T5g35x9O/o+L+AdvQ9JGim+E06SGjHAktSIAZakRgywJDVigCWpEQMsSY0YYElqxABLUiMGWJIaMcCS1IgBlqRGDLAkNdLpxXg0vydWXfL//StpNBngBv5x/U+0HkHSEPAUhCQ1YoAlqREDLEmNeA5YI23btm1MT0+zevVqdu3a1XocjRgDrJE2PT3NqVOnWo+hEeUpCElqxABLUiMGWJIaMcCS1IgBlqRGDLAkNWKAJakRAyxJjRhgSWrEAEtSIwZYkhoxwJLUiAGWpEYMsCQ10mmAk2xMcizJ8STb53n8xiQzSQ71Pn6hy3kkaZh0dj3gJGPAbuBaYAo4kGSyqo7MWfqHVbW1qzkkaVh1eQS8ATheVSeq6lFgL7Cpw+8nSReVLgN8GXCyb3uqt2+u1ya5N8ltSdbO90RJtiQ5mOTgzMxMF7NK0pLrMsCZZ1/N2f5T4Huq6krgL4EPz/dEVbWnqiaqamJ8fHyRx5SkNroM8BTQf0S7Bjjdv6CqvlZV/9Tb/F3ghzqcR5KGSpcBPgCsT7IuySpgMzDZvyDJ8/s2rwOOdjiPJA2Vzl4FUVVnk2wF9gNjwM1VdTjJTuBgVU0Cb0tyHXAWeAC4sat5JGnYdHpb+qraB+ybs29H3+fvAt7V5QySNKx8J5wkNWKAJakRAyxJjRhgSWrEAEtSI52+CkIC+PLOH2g9wnmdfeA5wErOPvCloZ3z8h1faD2COuIRsCQ1YoAlqREDLEmNGGBJasQAS1IjBliSGjHAktSIAZakRgywJDVigCWpEQMsSY0YYElqxABLUiMGWJIaMcCS1IgBlqRGDLAkNWKAJakRAyxJjRhgSWrEAEtSIwZYkhoxwJLUiAGWpEYMsCQ1YoAlqREDLEmNdBrgJBuTHEtyPMn2C6x7XZJKMtHlPJI0TFZe6MEkDwF1vser6rsu8LVjwG7gWmAKOJBksqqOzFl3KfA24J4nMbe0KJ73jCeAs71/paV1wQBX1aUASXYC08BHgAA3AJcu8NwbgONVdaL3HHuBTcCROet+FdgF3PRkh5eerpuufLD1CBphg56C+FdV9dtV9VBVfbOq/hvw2gW+5jLgZN/2VG/ftyS5ClhbVX92oSdKsiXJwSQHZ2ZmBhxZkobboAF+PMkNScaSrEhyA/D4Al+TefZ963RGkhXA+4FfWuibV9Weqpqoqonx8fEBR5ak4TZogH8GeAPwD72P1/f2XcgUsLZvew1wum/7UuBlwCeS3A/8S2DSP8RJGhUXPAd8TlXdz+z52yfjALA+yTrgFLCZvmhX1TeA553bTvIJ4KaqOvgkv48kXZQGOgJO8uIkH0vyxd72lUn+44W+pqrOAluB/cBR4NaqOpxkZ5Lrnu7gknSxG+gIGPhd4J3ABwGq6t4ktwC/dqEvqqp9wL45+3acZ+2rBpxFkpaFQc8BP7Oq/nbOvrOLPYwkjZJBA3wmyQvpvYohyeuAr3Q2lSSNgEFPQfwisAf4viSngPuYfTOGJOkpGjTAX6qqa5JcAqyoqoe6HEqSRsGgpyDuS7KH2dfqPtzhPJI0MgYN8EuAv2T2VMR9SX4ryY90N5YkLX8DBbiqHqmqW6vq3wBXAd8FfLLTySRpmRv4esBJfjTJbwOfBZ7B7FuTJUlP0UB/hEtyH3AIuBV4Z1X9Y6dTSdIIGPRVED9YVd/sdBJJGjEL3RFjW1XtAt6T5NvujFFVb+tsMkla5hY6Aj7a+9crlEnSIlvolkR/2vv03qr63BLMI0kjY9BXQbwvyd8l+dUkL+10IkkaEYO+DvjHgFcBM8CeJF9Y6HrAkqQLG/h1wFU1XVW/CbyF2ZekzXtdX0nSYAa9I8b3J3l3744YvwX8NbP3eJMkPUWDvg74fwAfBX6iqk4vtFiStLAFA5xkDPjfVfUbSzCPJI2MBU9BVNXjwHOTrFqCeSRpZAx8QXbgriSTwLeuA1FV7+tkKkkaAYMG+HTvYwVwaXfjSNLoGCjAVfUrXQ8iSaNm0MtR3knvjsj9qurViz6RJI2IQU9B3NT3+TOA1wJnF38cSRodg56C+MycXXcl8ZZEkvQ0DHoK4jl9myuACWB1JxNJ0ogY9BTEZ/h/54DPAvcDb+piIEkaFQvdEeOHgZNVta63/UZmz//eDxzpfDpJWsYWeifcB4FHAZK8EvgvwIeBbwB7uh1Nkpa3hU5BjFXVA73PfxrYU1W3A7cnOdTtaJK0vC10BDyW5Fykfxz4eN9jg54/liTNY6GIfhT4ZJIzwCPApwGSvIjZ0xCSpKfogkfAVfUe4JeADwE/UlXnXgmxAnjrQk+eZGOSY0mOJ9k+z+Nv6d3e6FCSv0pyxZP/ESTp4rTgaYSqunuefX+/0Nf1riO8G7gWmAIOJJmsqv5XT9xSVb/TW38d8D5g44CzS9JFbeB7wj0FG4DjVXWiqh4F9gKb+hdU1Tf7Ni9hnutNSNJy1eUf0i4DTvZtTwGvmLsoyS8C7wBWAfNe3CfJFmALwOWXX77og0pSC10eAWeeffNdUW13Vb0Q+GVg3lvdV9Weqpqoqonx8fFFHlOS2ugywFPA2r7tNcxe1P189gI/1eE8kjRUugzwAWB9knW9+8ltBib7FyRZ37f5k8D/6nAeSRoqnZ0DrqqzSbYC+4Ex4OaqOpxkJ3CwqiaBrUmuAR4Dvg68sat5JGnYdPputqraB+ybs29H3+dv7/L7S9Iw8+3EkobCtm3bmJ6eZvXq1ezatav1OEvCAEsaCtPT05w6dar1GEuqyz/CSZIuwABLUiMGWJIaMcCS1IgBlqRGDLAkNWKAJakRAyxJjRhgSWrEAEtSIwZYkhoxwJLUiAGWpEYMsCQ1YoAlqREDLEmNeEF2acRc/YGrW48wr1UPrmIFKzj54MmhnfGut961qM/nEbAkNWKAJakRAyxJjRhgSWrEAEtSIwZYkhoxwJLUiAGWpEYMsCQ1YoAlqREDLEmNGGBJasQAS1IjBliSGuk0wEk2JjmW5HiS7fM8/o4kR5Lcm+RjSV7Q5TySNEw6C3CSMWA38BrgCuD6JFfMWfY5YKKqrgRuA3Z1NY8kDZsuj4A3AMer6kRVPQrsBTb1L6iqO6vq//Q27wbWdDiPpCFWzyyeuOQJ6pnVepQl0+UdMS4DTvZtTwGvuMD6NwF/Pt8DSbYAWwAuv/zyxZpP0hB57OrHWo+w5Lo8As48++b9T1uSnwUmgPfO93hV7amqiaqaGB8fX8QRJamdLo+Ap4C1fdtrgNNzFyW5BvgPwI9W1T91OI8kDZUuj4APAOuTrEuyCtgMTPYvSHIV8EHguqr6aoezSNLQ6SzAVXUW2ArsB44Ct1bV4SQ7k1zXW/Ze4FnAHyU5lGTyPE8nSctOp7elr6p9wL45+3b0fX5Nl99fkoaZ74STpEYMsCQ1YoAlqREDLEmNGGBJasQAS1IjBliSGjHAktSIAZakRgywJDVigCWpEQMsSY0YYElqxABLUiMGWJIaMcCS1IgBlqRGDLAkNWKAJakRAyxJjRhgSWrEAEtSIwZYkhoxwJLUiAGWpEYMsCQ1YoAlqREDLEmNGGBJasQAS1IjBliSGjHAktSIAZakRjoNcJKNSY4lOZ5k+zyPvzLJZ5OcTfK6LmeRpGHTWYCTjAG7gdcAVwDXJ7lizrIvAzcCt3Q1hyQNq5UdPvcG4HhVnQBIshfYBBw5t6Cq7u899kSHc0jSUOryFMRlwMm+7anevictyZYkB5McnJmZWZThJKm1LgOcefbVU3miqtpTVRNVNTE+Pv40x5Kk4dBlgKeAtX3ba4DTHX4/SbqodBngA8D6JOuSrAI2A5Mdfj9Juqh0FuCqOgtsBfYDR4Fbq+pwkp1JrgNI8sNJpoDXAx9McrireSRp2HT5Kgiqah+wb86+HX2fH2D21IQkjRzfCSdJjRhgSWrEAEtSIwZYkhoxwJLUiAGWpEYMsCQ1YoAlqREDLEmNGGBJasQAS1IjBliSGjHAktSIAZakRgywJDVigCWpEQMsSY0YYElqxABLUiMGWJIaMcCS1IgBlqRGDLAkNWKAJakRAyxJjRhgSWrEAEtSIwZYkhoxwJLUiAGWpEYMsCQ1YoAlqREDLEmNdBrgJBuTHEtyPMn2eR7/Z0n+sPf4PUm+p8t5JGmYdBbgJGPAbuA1wBXA9UmumLPsTcDXq+pFwPuB/9rVPJI0bLo8At4AHK+qE1X1KLAX2DRnzSbgw73PbwN+PEk6nEmShsbKDp/7MuBk3/YU8Irzramqs0m+ATwXONO/KMkWYEtv8+EkxzqZeGk9jzk/57DIr7+x9QhLbWh/FwD855E6Jhnq30XeNvDv4o6q2rjQoi4DPN+k9RTWUFV7gD2LMdSwSHKwqiZazyF/F8Nk1H4XXZ6CmALW9m2vAU6fb02SlcA/Bx7ocCZJGhpdBvgAsD7JuiSrgM3A5Jw1k8C5/999HfDxqvq2I2BJWo46OwXRO6e7FdgPjAE3V9XhJDuBg1U1Cfwe8JEkx5k98t3c1TxDaFmdUrnI+bsYHiP1u4gHnJLUhu+Ek6RGDLAkNWKAl1iSm5N8NckXW88y6pKsTXJnkqNJDid5e+uZRlWSZyT52ySf7/0ufqX1TEvBc8BLLMkrgYeB36+ql7WeZ5QleT7w/Kr6bJJLgc8AP1VVRxqPNnJ674C9pKoeTvIdwF8Bb6+quxuP1imPgJdYVX0KX+s8FKrqK1X12d7nDwFHmX13ppZYzXq4t/kdvY9lf3RogCWgdyW+q4B72k4yupKMJTkEfBX4i6pa9r8LA6yRl+RZwO3Av62qb7aeZ1RV1eNV9XJm3zW7IcmyP0VngDXSeucbbwf+oKr+uPU8gqp6EPgEsODFbC52Blgjq/eHn98DjlbV+1rPM8qSjCd5du/z7wSuAf6u7VTdM8BLLMlHgb8BXpJkKsmbWs80wq4Gfg54dZJDvY9/3XqoEfV84M4k9zJ7HZm/qKo/azxT53wZmiQ14hGwJDVigCWpEQMsSY0YYElqxABLUiMGWMtGksd7LyX7YpI/SvLMC6x9d5KblnI+aS4DrOXkkap6ee8qc48Cb2k9kHQhBljL1aeBFwEk+fkk9/auNfuRuQuTvDnJgd7jt587ck7y+t7R9OeTfKq376W969Ye6j3n+iX9qbSs+EYMLRtJHq6qZyVZyez1He4APgX8MXB1VZ1J8pyqeiDJu4GHq+rXkzy3qr7We45fA/6hqj6Q5AvAxqo6leTZVfVgkg8Ad1fVH/Tu9j1WVY80+YF10fMIWMvJd/YuZ3gQ+DKz13l4NXBbVZ0BqKr5rsX8siSf7gX3BuClvf13AR9K8mZm7+wNs28j//dJfhl4gfHV09HZbemlBh7pXc7wW3oX3Fnof/M+xOydMD6f5EbgVQBV9ZYkrwB+EjiU5OVVdUuSe3r79if5har6+CL/HBoRHgFrufsY8IYkzwVI8px51lwKfKV3acobzu1M8sKquqeqdgBngLVJvhc4UVW/CUwCV3b+E2jZ8ghYy1pVHU7yHuCTSR4HPgfcOGfZf2L2ThhfAr7AbJAB3tv7I1uYDfnnge3AzyZ5DJgGdnb+Q2jZ8o9wktSIpyAkqREDLEmNGGBJasQAS1IjBliSGjHAktSIAZakRv4vtQkUJqVdxQwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.catplot(x = \"Pclass\", y = \"Survived\", kind = \"bar\", data = train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaMAAAFgCAYAAAAW6RbuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAF09JREFUeJzt3X+0XWV95/H3h4QUC1GWkmlY/BCqwSkiSomotWNRKRNsFzj1x0DxBzMOjDMFO6vFDFOVUpA6Ezu2VYE2bRnUZaX4ozPRxUit4o+hogT5ZUDaDCgkcCUpgqCMGPjOH2dDrzc33ENydp6Te96vtc66Z+/9nH2/Z5217uc+z9n7eVJVSJLU0m6tC5AkyTCSJDVnGEmSmjOMJEnNGUaSpOYMI0lSc4aRJKk5w0iS1JxhJElqbmHrAp6sFStW1Gc/+9nWZUjSXNK6gF3JLtcz2rx5c+sSJEkjtsuFkSRp/jGMJEnNGUaSpOYMI0lSc4aRJKk5w0iS1JxhJElqzjCSJDVnGEmSmustjJJcnOSeJN/cxvEkeX+S9UluTPLzfdUiSRpvffaMLgFWPMHx44Bl3eM04KIea5EkjbHeJkqtqi8nOegJmpwAfLiqCrg6yd5J9q2qu/uqab5auXIlU1NTLF26lFWrVrUuR5KetJazdu8H3Dlte0O3b6swSnIag94TBx544E4pblcyNTXFxo0bW5chSdut5QUMs02vXrM1rKrVVbW8qpYvWbKk57IkSTtbyzDaABwwbXt/4K5GtUiSGmoZRmuAN3VX1b0YuN/viyRpMvX2nVGSjwFHA/sk2QD8LrA7QFX9CXA58CpgPfBD4N/0VYskabz1eTXdSXMcL+A3+vr9kqRdhzMwSJKaa3lptzTveM+XtH0MI2mEvOdL2j4O00mSmrNn1Mgd5z5vZOfacu/TgYVsufc7IzvvgWffNJLzSNIw7BlJkpozjCRJzRlGkqTmDCNJUnOGkSSpOcNIktScYSRJas4wkiQ1ZxhJkppzBoZ5YJ89HgW2dD8laddjGM0DZx5+X+sSJGmHOEwnSWrOnpEmnpPWSu3ZM5IkNWcYSZKaM4wkSc0ZRpKk5gwjSVJzhpEkqTnDSJLUnGEkSWrOMJIkNWcYSZKaM4wkSc0ZRpKk5gwjSVJzhpEkqTnDSJLUnGEkSWrOMJIkNWcYSZKaM4wkSc0tbF2ANJ/ss8ejwJbup6RhGUbSCJ15+H2tS5B2SQ7TSZKaM4wkSc0ZRpKk5gwjSVJzhpEkqTnDSJLUnGEkSWrOMJIkNWcYSZKaM4wkSc31GkZJViS5Ncn6JGfNcvzAJFcmuS7JjUle1Wc9kqTx1FsYJVkAXAAcBxwKnJTk0BnN3glcVlVHACcCF/ZVjyRpfPXZMzoKWF9Vt1XVw8ClwAkz2hTw1O7504C7eqxHkjSm+gyj/YA7p21v6PZNdw7whiQbgMuBM2Y7UZLTkqxNsnbTpk191CpJaqjPMMos+2rG9knAJVW1P/Aq4CNJtqqpqlZX1fKqWr5kyZIeSpUktdRnGG0ADpi2vT9bD8O9BbgMoKq+CuwB7NNjTZKkMdRnGF0DLEtycJJFDC5QWDOjzR3AKwGS/ByDMHIcTpImTG9hVFVbgNOBK4BbGFw1ty7JuUmO75r9NnBqkhuAjwGnVNXMoTxJ0jzX67LjVXU5gwsTpu87e9rzm4GX9lmDJGn8OQODJKk5w0iS1JxhJElqzjCSJDVnGEmSmjOMJEnNGUaSpOYMI0lSc4aRJKk5w0iS1JxhJElqzjCSJDVnGEmSmjOMJEnNGUaSpOYMI0lSc4aRJKk5w0iS1JxhJElqzjCSJDVnGEmSmjOMJEnNGUaSpOYMI0lSc4aRJKk5w0iS1JxhJElqzjCSJDVnGEmSmjOMJEnNGUaSpOYMI0lSc4aRJKk5w0iS1JxhJElqzjCSJDVnGEmSmjOMJEnNGUaSpOYMI0lSc4aRJKk5w0iS1JxhJElqzjCSJDVnGEmSmjOMJEnNGUaSpOYMI0lSc4aRJKm5XsMoyYoktyZZn+SsbbR5fZKbk6xL8pd91iNJGk8L+zpxkgXABcAvAxuAa5Ksqaqbp7VZBvwX4KVV9b0k/6yveiRJ46vPntFRwPqquq2qHgYuBU6Y0eZU4IKq+h5AVd3TYz2SpDHVZxjtB9w5bXtDt2+6Q4BDklyV5OokK2Y7UZLTkqxNsnbTpk09lStJaqXPMMos+2rG9kJgGXA0cBLw50n23upFVauranlVLV+yZMnIC5UktdXbd0YMekIHTNveH7hrljZXV9WPgduT3MognK7psS5JE2LlypVMTU2xdOlSVq1a1bocPYE+e0bXAMuSHJxkEXAisGZGm/8JvBwgyT4Mhu1u67EmSRNkamqKjRs3MjU11boUzeEJe0ZJHmDrobXHVdVTn+DYliSnA1cAC4CLq2pdknOBtVW1pjt2bJKbgUeAt1fVP27H+5Ak7cKeMIyqajFAFyBTwEcYfBd0MrB4rpNX1eXA5TP2nT3teQG/1T0kSRNq2GG6f1lVF1bVA1X1/aq6CHhNn4VJkibHsGH0SJKTkyxIsluSkxkMq0mStMOGDaNfB14PfLd7vK7bJ0nSDhvq0u6q+jZbz54gSdJIDNUzSnJIks8n+Wa3fXiSd/ZbmiRpUgw7TPdnDCY0/TFAVd3I4L4hSZJ22LBh9NNV9fUZ+7aMuhhJ0mQaNow2J3kW3Q2wSV4L3N1bVZKkiTLs3HS/AawG/nmSjcDtDG58lSRphw0bRt+pqmOS7AnsVlUP9FmUJGmyDDtMd3uS1cCLgQd7rEeStJ2SvCPJuiQ3Jrk+yYta1zSsYcPoOcDfMhiuuz3JB5P8Yn9lSZKejCQvAX4V+PmqOhw4hp9c4HSsDRVGVfVQVV1WVb8GHAE8FfhSr5VJkp6MfYHNVfUjgKraXFV3JTkyyZeSXJvkiiT7JlmY5JokRwMkeU+S81sWP/R6Rkl+KcmFwDeAPRhMDyRJGg9/AxyQ5O+TXNj9zd4d+ADw2qo6ErgYOL+qtgCnABcl+WVgBfB7rQqHIS9gSHI7cD1wGYM1h37Qa1WSpCelqh5MciTwLxgsWvpXwLuBw4DPJYHB2nJ3d+3XJfkI8GngJVX1cJPCO8NeTff8qvp+r5VIknZIVT0CfBH4YpKbGHzPv66qXrKNlzwPuA/4mZ1T4bbNtdLryqpaBZyfZKsVX6vqbb1VJkkaWpLnAI9W1T90u14A3MJgNe2XVNVXu2G7Q7pe0a8BzwBeBnwmyVFVdV+b6ufuGd3S/VzbdyGSpB2yF/CBJHszmK5tPXAagwkL3p/kaQz+5v9Rku8C/xV4ZVXdmeSDwB8Db25T+tzLjn+6e3pjVV23E+qRJG2HqroW+IVZDm1m0PuZ6ZBpr31/X3UNa9ir6d6X5FtJzkvy3F4rkiRNnGHvM3o5cDSwCVid5CbXM5IkjcrQ9xlV1VTXlXsrg8u8z+6tKknSRBl2pdefS3JOt9LrB4G/A/bvtTJJ0sQY9j6j/wF8DDi2qu7qsR5JE+6Oc583snNtuffpwEK23PudkZ33wLNvGsl59JPmDKMkC4D/W1V/vBPqkSRNoDmH6bo7ep+RZNFOqEeSNCaSHJ3kMzvjdw29uB5wVZI1wOPz0lXV+3qpSpLmoSPf/uGtZrLZEde+900Z5flaGvZquruAz3TtF097SJLGWJKDuvtE/zzJN5N8NMkxSa5K8g9Jjuoef5fkuu7nc2Y5z55JLu6WnrguyQmjrHOonlFVNZ1aXJK0Q54NvI7B9EDXAL8O/CJwPPA7wJuAl1XVliTHAL8PvGbGOd4BfKGq/m035dDXk/ztqFZxGHYJiSuB2SZKfcUoipAk9er2qroJIMk64PNVVd3M3gcBTwM+lGQZg7/1u89yjmOB45Oc2W3vARzIP81hukOG/c7ozGnP92CQmFtGUYAkqXc/mvb80WnbjzLIgfOAK6vqXyU5iMEyFDMFeE1V3dpHgcMO0107Y9dVSVx2XJLmh6cBG7vnp2yjzRXAGUnO6HpVR4xyAu1hZ2B4+rTHPklWAEtHVYQkqalVwHuSXMVgNdjZnMdg+O7Gbjae80ZZwLDDdNfyT98ZbQG+DbxllIVI0nzX4lLsqvo2g6XHH9s+ZRvHDpn2snd1x79IN2RXVQ8B/76vOuda6fWFwJ1VdXC3/WYG3xd9G7i5r6IkSZNlrmG6PwUeBkjyMuA9wIeA+xmsHihJ0g6ba5huQVXd2z3/18Dqqvok8Mkk1/db2vhYuXIlU1NTLF26lFWrVrUuR5LmnTnDKMnCqtoCvJLBDVPDvnbemJqaYuPGjXM3lCRtl7kC5WPAl5JsBh4CvgKQ5NkMhuokSdphTxhGVXV+ks8D+wJ/U1WPXVG3G3BG38VJkibDnENtVXX1LPv+vp9yJEmjluRtwH8AvlFVJ/dw/nOAB6vqD7b3HBPzvY8ktXbHuc8b6RISB55907D3Lf1H4Liqun2Uv3+UDCNJmseS/Anws8CaJJcCzwKex+Dv/zlV9b+SnAK8msHsC4cB/x1YBLyRwTx2r6qqe5OcyuBCtkXAeuCNVfXDGb/vWcAFwBLgh8CpVfWtueocdj0jSdIuqKreymBNupcDezJYBuKF3fZ7k+zZNT2MwdISRwHnAz+sqiOArzJYYgLgU1X1wqp6PoPZumebiWc1cEZVHclgku0Lh6nTnpEkTY5tLQMBg1m7HwAeSHI/8Olu/03A4d3zw5K8G9gb2IvB5KmPS7IX8AvAx5PHRxB/apjCDCNJmhyzLgOR5EXMvcwEwCXAq6vqhm5o7+gZ598NuK+qXvBkC3OYTtK8tc8ej/IzT9nCPns82rqUcfHYMhABSHLEk3z9YuDuJLsDW12VV1XfB25P8rru/Eny/GFObM9I0rx15uH3tS5h3JwH/BGDZSDCYNLrX30Sr38X8DXgOwyG7xbP0uZk4KIk72Sw5MSlwA1zndgwkqSd5Elcij1SVXXQtM2tloGoqksYDMFt1X76saq6CLholtefM+357cCKJ1tjr8N0SVYkuTXJ+iRnPUG71yapJMv7rEeSNJ56C6MkCxhca34ccChwUpJDZ2m3GHgbg66fJGkC9dkzOgpYX1W3VdXDDMYNT5il3XkMlrz9fz3WIkkaY32G0X7AndO2N3T7HtddyXFAVX3miU6U5LQka5Os3bRp0+grlSQ11WcYzfZF3ePzMiXZDfhD4LfnOlFVra6q5VW1fMmSJSMsUZI0DvoMow3AAdO292cwJcVjFjOYfuKLSb4NvJjB3ElexCBJE6bPMLoGWJbk4CSLgBOBNY8drKr7q2qfqjqou4zwauD4qlrbY02SpDHUWxh1S5WfzuCO31uAy6pqXZJzkxzf1++VJO16er3ptaouBy6fse/sbbQ9us9aJEnjy7npJEnNGUaSpOYMI0lSc/N2otQj3/7hkZ1r8eYHWADcsfmBkZ33r2eb61aSJpQ9I0lSc4aRJKk5w0iS1JxhJElqzjCSJDVnGEmSmjOMJEnNGUaSpOYMI0lSc4aRJKk5w0iS1JxhJElqzjCSJDVnGEmSmjOMJEnNGUaSpOYMI0lSc4aRJKk5w0iS1JxhJElqzjCSJDVnGEmSmjOMJEnNGUaSpOYMI0lSc4aRJKm5ha0L2BU8umjPn/gpSRotw2gIP1h2bOsSJGlec5hOktScYSRJas4wkiQ1ZxhJkpozjCRJzRlGkqTmDCNJUnOGkSSpOcNIktScYSRJas7pgLTLWblyJVNTUyxdupRVq1a1LkfSCBhG2uVMTU2xcePG1mVIGiGH6SRJzRlGkqTmDCNJUnOGkSSpOcNIktRcr2GUZEWSW5OsT3LWLMd/K8nNSW5M8vkkz+yzHknSeOotjJIsAC4AjgMOBU5KcuiMZtcBy6vqcOATgDeNSNIE6rNndBSwvqpuq6qHgUuBE6Y3qKorq+qH3ebVwP491iNJGlN9htF+wJ3Ttjd0+7blLcD/nu1AktOSrE2ydtOmTSMsUZI0DvoMo8yyr2ZtmLwBWA68d7bjVbW6qpZX1fIlS5aMsERJ0jjoczqgDcAB07b3B+6a2SjJMcA7gF+qqh/1WI8kaUz12TO6BliW5OAki4ATgTXTGyQ5AvhT4PiquqfHWiRJY6y3MKqqLcDpwBXALcBlVbUuyblJju+avRfYC/h4kuuTrNnG6SRJ81ivs3ZX1eXA5TP2nT3t+TF9/n5J0q7BGRgkSc25npGk7eZChxoVw0jSdnOhQ42Kw3SSpOYMI0lSc4aRJKk5vzPSTnHk2z88snMt3vwAC4A7Nj8wkvP+9eIdr0nSjrFnJElqzjCSJDVnGEmSmjOMJEnNGUaSpOYMI0lSc17aLU2Ycb7MHrzUflLZM5IkNWcYSZKaM4wkSc0ZRpKk5gwjSVJzhpEkqTnDSJLUnGEkSWrOMJIkNWcYSZKaczogSdvt0UV7/sRPaXsZRpK22w+WHdu6BM0ThpF2Of43Ls0/hpF2Of43Ls0/XsAgSWrOMJIkNWcYSZKaM4wkSc0ZRpKk5gwjSVJzhpEkqTnDSJLUnGEkSWrOMJIkNWcYSZKaM4wkSc0ZRpKk5gwjSVJzhpEkqTnDSJLUnGEkSWrOMJIkNWcYSZKaM4wkSc0ZRpKk5noNoyQrktyaZH2Ss2Y5/lNJ/qo7/rUkB/VZjyRpPPUWRkkWABcAxwGHAiclOXRGs7cA36uqZwN/CPy3vuqRJI2vPntGRwHrq+q2qnoYuBQ4YUabE4APdc8/AbwySXqsSZI0hhb2eO79gDunbW8AXrStNlW1Jcn9wDOAzdMbJTkNOK3bfDDJrb1UvBM9E/ZhxvscK787Of8T+FmMl3n0eXy2qlb0Wcp80mcYzfaJ1Xa0oapWA6tHUdS4SLK2qpa3rkN+FuPGz2My9TlMtwE4YNr2/sBd22qTZCHwNODeHmuSJI2hPsPoGmBZkoOTLAJOBNbMaLMGeHP3/LXAF6pqq56RJGl+622YrvsO6HTgCmABcHFVrUtyLrC2qtYAfwF8JMl6Bj2iE/uqZwzNq2HHXZyfxXjx85hAsSMiSWrNGRgkSc0ZRpKk5gyjnSzJxUnuSfLN1rVMuiQHJLkyyS1J1iX5zdY1TbIkeyT5epIbus/j91rXpJ3H74x2siQvAx4EPlxVh7WuZ5Il2RfYt6q+kWQxcC3w6qq6uXFpE6mbfWXPqnowye7A/wF+s6qublyadgJ7RjtZVX0Z76UaC1V1d1V9o3v+AHALg1lB1EANPNht7t49/G95QhhGEtDNGH8E8LW2lUy2JAuSXA/cA3yuqvw8JoRhpImXZC/gk8B/qqrvt65nklXVI1X1AgYzthyVxKHsCWEYaaJ13018EvhoVX2qdT0aqKr7gC8CTjQ6IQwjTazuC/O/AG6pqve1rmfSJVmSZO/u+VOAY4Bvta1KO4thtJMl+RjwVeA5STYkeUvrmibYS4E3Aq9Icn33eFXroibYvsCVSW5kMLfl56rqM41r0k7ipd2SpObsGUmSmjOMJEnNGUaSpOYMI0lSc4aRJKk5w0jzRpJHusuzv5nk40l++gnanpPkzJ1Zn6RtM4w0nzxUVS/oZkN/GHhr64IkDccw0nz1FeDZAEnelOTGbp2cj8xsmOTUJNd0xz/5WI8qyeu6XtYNSb7c7Xtut+bO9d05l+3UdyXNU970qnkjyYNVtVeShQzmm/ss8GXgU8BLq2pzkqdX1b1JzgEerKo/SPKMqvrH7hzvBr5bVR9IchOwoqo2Jtm7qu5L8gHg6qr6aJJFwIKqeqjJG5bmEXtGmk+e0i0/sBa4g8G8c68APlFVmwGqara1pA5L8pUufE4Gntvtvwq4JMmpwIJu31eB30nyn4FnGkTSaCxsXYA0Qg91yw88rpsMda7u/yUMVni9IckpwNEAVfXWJC8CfgW4PskLquovk3yt23dFkn9XVV8Y8fuQJo49I813nwden+QZAEmePkubxcDd3XISJz+2M8mzquprVXU2sBk4IMnPArdV1fuBNcDhvb8DaQLYM9K8VlXrkpwPfCnJI8B1wCkzmr2LwQqv3wFuYhBOAO/tLlAIg1C7ATgLeEOSHwNTwLm9vwlpAngBgySpOYfpJEnNGUaSpOYMI0lSc4aRJKk5w0iS1JxhJElqzjCSJDX3/wFpQxDSNijcKwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 430.5x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.catplot(x = \"Pclass\", y = \"Survived\", kind = \"bar\", hue=\"Sex\", data = train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets create a simple two variable logistic-regression model...\n",
    "X_train = train.loc[:, [\"Sex\", \"Pclass\"]]\n",
    "y_train = train[\"Survived\"]\n",
    "X_test = test.loc[:, [\"Sex\",\"Pclass\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Pclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex  Pclass\n",
       "0    male       3\n",
       "1  female       1\n",
       "2  female       3\n",
       "3  female       1\n",
       "4    male       3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.get_dummies(X_train, columns = [\"Sex\", \"Pclass\"], drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.get_dummies(X_test, columns = [\"Sex\", \"Pclass\"], drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sex_male  Pclass_2  Pclass_3\n",
       "0         1         0         1\n",
       "1         0         0         0\n",
       "2         0         0         1\n",
       "3         0         0         0\n",
       "4         1         0         1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sex_male  Pclass_2  Pclass_3\n",
       "0           1         0         1\n",
       "1           0         0         0\n",
       "2           0         0         1\n",
       "3           0         0         0\n",
       "4           1         0         1\n",
       "5           1         0         1\n",
       "6           1         0         0\n",
       "7           1         0         1\n",
       "8           0         0         1\n",
       "9           0         1         0\n",
       "10          0         0         1\n",
       "11          0         0         0\n",
       "12          1         0         1\n",
       "13          1         0         1\n",
       "14          0         0         1\n",
       "15          0         1         0\n",
       "16          1         0         1\n",
       "17          1         1         0\n",
       "18          0         0         1\n",
       "19          0         0         1\n",
       "20          1         1         0\n",
       "21          1         1         0\n",
       "22          0         0         1\n",
       "23          1         0         0\n",
       "24          0         0         1\n",
       "25          0         0         1\n",
       "26          1         0         1\n",
       "27          1         0         0\n",
       "28          0         0         1\n",
       "29          1         0         1\n",
       "..        ...       ...       ...\n",
       "861         1         1         0\n",
       "862         0         0         0\n",
       "863         0         0         1\n",
       "864         1         1         0\n",
       "865         0         1         0\n",
       "866         0         1         0\n",
       "867         1         0         0\n",
       "868         1         0         1\n",
       "869         1         0         1\n",
       "870         1         0         1\n",
       "871         0         0         0\n",
       "872         1         0         0\n",
       "873         1         0         1\n",
       "874         0         1         0\n",
       "875         0         0         1\n",
       "876         1         0         1\n",
       "877         1         0         1\n",
       "878         1         0         1\n",
       "879         0         0         0\n",
       "880         0         1         0\n",
       "881         1         0         1\n",
       "882         0         0         1\n",
       "883         1         1         0\n",
       "884         1         0         1\n",
       "885         0         0         1\n",
       "886         1         1         0\n",
       "887         0         0         0\n",
       "888         0         0         1\n",
       "889         1         0         0\n",
       "890         1         0         1\n",
       "\n",
       "[891 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'max_iter': 100,\n",
       " 'multi_class': 'ovr',\n",
       " 'n_jobs': 1,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': None,\n",
       " 'solver': 'liblinear',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(solver = \"liblinear\")\n",
    "logreg.get_params()\n",
    "\n",
    "#note that C is the regularization parameter for logistic regression \n",
    "#(the smaller the value of C, the larger the amount of regularization)\n",
    "\n",
    "#penalty is l2 or l1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.48809433, -0.67634771, -1.7159975 ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7867564534231201"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logreg.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "logreg.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.10496527, 0.58537091, 0.24906911, 0.10496527, 0.58537091,\n",
       "       0.10496527, 0.58537091, 0.24906911, 0.58537091, 0.10496527,\n",
       "       0.10496527, 0.39478666, 0.88704025, 0.24906911, 0.88704025,\n",
       "       0.79971453, 0.24906911, 0.10496527, 0.58537091, 0.58537091,\n",
       "       0.39478666, 0.10496527, 0.88704025, 0.39478666, 0.88704025,\n",
       "       0.10496527, 0.88704025, 0.10496527, 0.39478666, 0.10496527,\n",
       "       0.24906911, 0.24906911, 0.58537091, 0.58537091, 0.39478666,\n",
       "       0.10496527, 0.58537091, 0.58537091, 0.10496527, 0.10496527,\n",
       "       0.10496527, 0.39478666, 0.10496527, 0.79971453, 0.88704025,\n",
       "       0.10496527, 0.39478666, 0.10496527, 0.88704025, 0.58537091,\n",
       "       0.39478666, 0.24906911, 0.79971453, 0.88704025, 0.24906911,\n",
       "       0.10496527, 0.10496527, 0.10496527, 0.10496527, 0.88704025,\n",
       "       0.10496527, 0.24906911, 0.10496527, 0.58537091, 0.39478666,\n",
       "       0.79971453, 0.58537091, 0.39478666, 0.39478666, 0.88704025,\n",
       "       0.58537091, 0.10496527, 0.58537091, 0.39478666, 0.88704025,\n",
       "       0.39478666, 0.10496527, 0.88704025, 0.24906911, 0.58537091,\n",
       "       0.10496527, 0.39478666, 0.39478666, 0.10496527, 0.24906911,\n",
       "       0.10496527, 0.58537091, 0.58537091, 0.58537091, 0.24906911,\n",
       "       0.58537091, 0.10496527, 0.88704025, 0.10496527, 0.39478666,\n",
       "       0.10496527, 0.88704025, 0.10496527, 0.58537091, 0.10496527,\n",
       "       0.88704025, 0.24906911, 0.10496527, 0.10496527, 0.58537091,\n",
       "       0.10496527, 0.10496527, 0.10496527, 0.10496527, 0.24906911,\n",
       "       0.24906911, 0.58537091, 0.88704025, 0.58537091, 0.88704025,\n",
       "       0.10496527, 0.10496527, 0.58537091, 0.39478666, 0.79971453,\n",
       "       0.79971453, 0.10496527, 0.88704025, 0.10496527, 0.10496527,\n",
       "       0.58537091, 0.10496527, 0.58537091, 0.24906911, 0.10496527,\n",
       "       0.10496527, 0.39478666, 0.58537091, 0.10496527, 0.10496527,\n",
       "       0.10496527, 0.10496527, 0.24906911, 0.58537091, 0.10496527,\n",
       "       0.58537091, 0.88704025, 0.39478666, 0.24906911, 0.39478666,\n",
       "       0.10496527, 0.39478666, 0.10496527, 0.39478666, 0.24906911,\n",
       "       0.88704025, 0.10496527, 0.10496527, 0.58537091, 0.10496527,\n",
       "       0.10496527, 0.88704025, 0.58537091, 0.39478666, 0.58537091,\n",
       "       0.58537091, 0.10496527, 0.79971453, 0.10496527, 0.24906911,\n",
       "       0.58537091, 0.39478666, 0.10496527, 0.88704025, 0.58537091,\n",
       "       0.10496527, 0.10496527, 0.10496527, 0.10496527, 0.10496527,\n",
       "       0.79971453, 0.79971453, 0.39478666, 0.79971453, 0.88704025,\n",
       "       0.24906911, 0.39478666, 0.88704025, 0.10496527, 0.88704025,\n",
       "       0.24906911, 0.79971453, 0.10496527, 0.58537091, 0.24906911,\n",
       "       0.24906911, 0.39478666, 0.10496527, 0.24906911, 0.24906911,\n",
       "       0.10496527, 0.39478666, 0.58537091, 0.24906911, 0.58537091,\n",
       "       0.58537091, 0.10496527, 0.39478666, 0.79971453, 0.24906911,\n",
       "       0.39478666, 0.58537091, 0.24906911, 0.88704025, 0.10496527,\n",
       "       0.10496527, 0.10496527, 0.24906911, 0.79971453, 0.58537091,\n",
       "       0.39478666, 0.58537091, 0.39478666, 0.88704025, 0.10496527,\n",
       "       0.79971453, 0.10496527, 0.79971453, 0.10496527, 0.88704025,\n",
       "       0.58537091, 0.10496527, 0.58537091, 0.10496527, 0.24906911,\n",
       "       0.24906911, 0.88704025, 0.10496527, 0.10496527, 0.39478666,\n",
       "       0.10496527, 0.39478666, 0.10496527, 0.79971453, 0.88704025,\n",
       "       0.88704025, 0.79971453, 0.39478666, 0.10496527, 0.10496527,\n",
       "       0.39478666, 0.79971453, 0.24906911, 0.79971453, 0.58537091,\n",
       "       0.79971453, 0.10496527, 0.39478666, 0.10496527, 0.10496527,\n",
       "       0.10496527, 0.10496527, 0.10496527, 0.79971453, 0.10496527,\n",
       "       0.10496527, 0.10496527, 0.79971453, 0.58537091, 0.24906911,\n",
       "       0.10496527, 0.39478666, 0.10496527, 0.58537091, 0.10496527,\n",
       "       0.39478666, 0.10496527, 0.88704025, 0.58537091, 0.10496527,\n",
       "       0.79971453, 0.24906911, 0.24906911, 0.24906911, 0.24906911,\n",
       "       0.58537091, 0.10496527, 0.58537091, 0.58537091, 0.58537091,\n",
       "       0.10496527, 0.10496527, 0.39478666, 0.10496527, 0.10496527,\n",
       "       0.39478666, 0.58537091, 0.10496527, 0.39478666, 0.10496527,\n",
       "       0.10496527, 0.79971453, 0.10496527, 0.39478666, 0.10496527,\n",
       "       0.10496527, 0.24906911, 0.24906911, 0.10496527, 0.58537091,\n",
       "       0.88704025, 0.39478666, 0.10496527, 0.39478666, 0.58537091,\n",
       "       0.10496527, 0.10496527, 0.10496527, 0.58537091, 0.88704025,\n",
       "       0.58537091, 0.39478666, 0.24906911, 0.10496527, 0.24906911,\n",
       "       0.10496527, 0.10496527, 0.24906911, 0.39478666, 0.88704025,\n",
       "       0.10496527, 0.79971453, 0.39478666, 0.24906911, 0.24906911,\n",
       "       0.79971453, 0.39478666, 0.10496527, 0.58537091, 0.10496527,\n",
       "       0.39478666, 0.24906911, 0.10496527, 0.24906911, 0.10496527,\n",
       "       0.24906911, 0.10496527, 0.10496527, 0.88704025, 0.10496527,\n",
       "       0.58537091, 0.24906911, 0.58537091, 0.24906911, 0.79971453,\n",
       "       0.88704025, 0.24906911, 0.24906911, 0.24906911, 0.58537091,\n",
       "       0.39478666, 0.88704025, 0.10496527, 0.10496527, 0.58537091,\n",
       "       0.10496527, 0.79971453, 0.79971453, 0.10496527, 0.88704025,\n",
       "       0.58537091, 0.10496527, 0.58537091, 0.88704025, 0.24906911,\n",
       "       0.24906911, 0.88704025, 0.39478666, 0.24906911, 0.88704025,\n",
       "       0.88704025, 0.58537091, 0.24906911, 0.39478666, 0.10496527,\n",
       "       0.10496527, 0.10496527, 0.58537091, 0.58537091, 0.24906911,\n",
       "       0.79971453, 0.10496527, 0.24906911, 0.10496527, 0.10496527,\n",
       "       0.39478666, 0.88704025, 0.10496527, 0.24906911, 0.10496527,\n",
       "       0.88704025, 0.10496527, 0.88704025, 0.10496527, 0.10496527,\n",
       "       0.88704025, 0.24906911, 0.88704025, 0.39478666, 0.39478666,\n",
       "       0.24906911, 0.24906911, 0.39478666, 0.58537091, 0.58537091,\n",
       "       0.58537091, 0.88704025, 0.58537091, 0.10496527, 0.88704025,\n",
       "       0.10496527, 0.10496527, 0.10496527])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.06085883])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.48809433, -0.67634771, -1.7159975 ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sex_male</td>\n",
       "      <td>-2.488094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pclass_2</td>\n",
       "      <td>-0.676348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pclass_3</td>\n",
       "      <td>-1.715997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Variable    Weight\n",
       "0  Sex_male -2.488094\n",
       "1  Pclass_2 -0.676348\n",
       "2  Pclass_3 -1.715997"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs = pd.DataFrame({\n",
    "    \"Variable\":X_train.columns,\n",
    "    \"Weight\":logreg.coef_[0]\n",
    "})\n",
    "coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.143233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.060859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.344861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.060859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.143233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0 -2.143233\n",
       "1  2.060859\n",
       "2  0.344861\n",
       "3  2.060859\n",
       "4 -2.143233"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = X_train.dot(logreg.coef_.T) + logreg.intercept_\n",
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.104965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.887040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.585371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.887040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.104965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0  0.104965\n",
       "1  0.887040\n",
       "2  0.585371\n",
       "3  0.887040\n",
       "4  0.104965"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(output).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = logreg.predict(X_test)\n",
    "\n",
    "lm_predictions = pd.DataFrame({\n",
    "    \"PassengerID\":test.PassengerId,\n",
    "    \"Survived\":preds\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerID</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerID  Survived\n",
       "0          892         0\n",
       "1          893         1\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_predictions.to_csv(\"/Users/theodoreplotkin/desktop/postmalone/GA_Data_Science/GA_github_repo/Untitled Folder/submissions.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73916994, 0.02748232, 0.23334775])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = pd.DataFrame({\n",
    "    \"Features\":X_train.columns,\n",
    "    \"Importance\":rf.feature_importances_\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sex_male</td>\n",
       "      <td>0.739170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pclass_2</td>\n",
       "      <td>0.027482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pclass_3</td>\n",
       "      <td>0.233348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Features  Importance\n",
       "0  Sex_male    0.739170\n",
       "1  Pclass_2    0.027482\n",
       "2  Pclass_3    0.233348"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.87438318, 0.12561682],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.63896895, 0.36103105],\n",
       "       [0.02829872, 0.97170128],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.02829872, 0.97170128],\n",
       "       [0.11411673, 0.88588327],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.63896895, 0.36103105],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.02829872, 0.97170128],\n",
       "       [0.63896895, 0.36103105],\n",
       "       [0.02829872, 0.97170128],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.02829872, 0.97170128],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.63896895, 0.36103105],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.63896895, 0.36103105],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.63896895, 0.36103105],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.11411673, 0.88588327],\n",
       "       [0.02829872, 0.97170128],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.63896895, 0.36103105],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.02829872, 0.97170128],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.63896895, 0.36103105],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.11411673, 0.88588327],\n",
       "       [0.02829872, 0.97170128],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.02829872, 0.97170128],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.63896895, 0.36103105],\n",
       "       [0.11411673, 0.88588327],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.63896895, 0.36103105],\n",
       "       [0.63896895, 0.36103105],\n",
       "       [0.02829872, 0.97170128],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.63896895, 0.36103105],\n",
       "       [0.02829872, 0.97170128],\n",
       "       [0.63896895, 0.36103105],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.02829872, 0.97170128],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.63896895, 0.36103105],\n",
       "       [0.63896895, 0.36103105],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.02829872, 0.97170128],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.63896895, 0.36103105],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.02829872, 0.97170128],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.02829872, 0.97170128],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.02829872, 0.97170128],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.02829872, 0.97170128],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.63896895, 0.36103105],\n",
       "       [0.11411673, 0.88588327],\n",
       "       [0.11411673, 0.88588327],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.02829872, 0.97170128],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.63896895, 0.36103105],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.02829872, 0.97170128],\n",
       "       [0.63896895, 0.36103105],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.63896895, 0.36103105],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.63896895, 0.36103105],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.63896895, 0.36103105],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.02829872, 0.97170128],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.02829872, 0.97170128],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.63896895, 0.36103105],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.11411673, 0.88588327],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.63896895, 0.36103105],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.02829872, 0.97170128],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.11411673, 0.88588327],\n",
       "       [0.11411673, 0.88588327],\n",
       "       [0.63896895, 0.36103105],\n",
       "       [0.11411673, 0.88588327],\n",
       "       [0.02829872, 0.97170128],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.63896895, 0.36103105],\n",
       "       [0.02829872, 0.97170128],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.02829872, 0.97170128],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.11411673, 0.88588327],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.63896895, 0.36103105],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.63896895, 0.36103105],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.63896895, 0.36103105],\n",
       "       [0.11411673, 0.88588327],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.63896895, 0.36103105],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.02829872, 0.97170128],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.11411673, 0.88588327],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.63896895, 0.36103105],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.63896895, 0.36103105],\n",
       "       [0.02829872, 0.97170128],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.11411673, 0.88588327],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.11411673, 0.88588327],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.02829872, 0.97170128],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.02829872, 0.97170128],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.63896895, 0.36103105],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.63896895, 0.36103105],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.11411673, 0.88588327],\n",
       "       [0.02829872, 0.97170128],\n",
       "       [0.02829872, 0.97170128],\n",
       "       [0.11411673, 0.88588327],\n",
       "       [0.63896895, 0.36103105],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.63896895, 0.36103105],\n",
       "       [0.11411673, 0.88588327],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.11411673, 0.88588327],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.11411673, 0.88588327],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.63896895, 0.36103105],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.11411673, 0.88588327],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.11411673, 0.88588327],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.63896895, 0.36103105],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.63896895, 0.36103105],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.02829872, 0.97170128],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.11411673, 0.88588327],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.63896895, 0.36103105],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.63896895, 0.36103105],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.63896895, 0.36103105],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.11411673, 0.88588327],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.63896895, 0.36103105],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.02829872, 0.97170128],\n",
       "       [0.63896895, 0.36103105],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.63896895, 0.36103105],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.02829872, 0.97170128],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.63896895, 0.36103105],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.63896895, 0.36103105],\n",
       "       [0.02829872, 0.97170128],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.11411673, 0.88588327],\n",
       "       [0.63896895, 0.36103105],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.11411673, 0.88588327],\n",
       "       [0.63896895, 0.36103105],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.63896895, 0.36103105],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.02829872, 0.97170128],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.11411673, 0.88588327],\n",
       "       [0.02829872, 0.97170128],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.63896895, 0.36103105],\n",
       "       [0.02829872, 0.97170128],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.11411673, 0.88588327],\n",
       "       [0.11411673, 0.88588327],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.02829872, 0.97170128],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.02829872, 0.97170128],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.02829872, 0.97170128],\n",
       "       [0.63896895, 0.36103105],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.02829872, 0.97170128],\n",
       "       [0.02829872, 0.97170128],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.63896895, 0.36103105],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.11411673, 0.88588327],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.63896895, 0.36103105],\n",
       "       [0.02829872, 0.97170128],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.02829872, 0.97170128],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.02829872, 0.97170128],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.02829872, 0.97170128],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.02829872, 0.97170128],\n",
       "       [0.63896895, 0.36103105],\n",
       "       [0.63896895, 0.36103105],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.85286569, 0.14713431],\n",
       "       [0.63896895, 0.36103105],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.02829872, 0.97170128],\n",
       "       [0.49536945, 0.50463055],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.02829872, 0.97170128],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.87438318, 0.12561682],\n",
       "       [0.87438318, 0.12561682]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_preds = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_submissions = pd.DataFrame({\n",
    "    \"PassengerID\":test.PassengerId,\n",
    "    \"Survived\":rf_preds\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_submissions.to_csv(\"/Users/theodoreplotkin/desktop/postmalone/GA_Data_Science/GA_github_repo/Untitled Folder/submissions_new.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 ** 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5, 8}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train[\"SibSp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pick varibles/make transforms\n",
    "#put into train/test set \n",
    "#then get dummies for unordered categoricals in the train/test sets\n",
    "\n",
    "#so Sex/Pclass are two important dummies\n",
    "#lets also use Age (but 177 are missing, can possibly impute), Fare\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.69911764705882"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"Age\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for items in train[\"Age\"]:\n",
    "    if items == \"nan\":\n",
    "        train[\"Age\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "empty = []\n",
    "for i in train.index.tolist():\n",
    "    if type(train[\"Age\"][i]) != \"numpy.float64\":\n",
    "        train[\"Age\"][i] = train[\"Age\"].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"Age\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(train[\"Age\"][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = train.loc[:, \"Age\",\"Sex\",\"Fare\",\"PClass\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = []\n",
    "for names in train[\"Name\"]:\n",
    "    titles.append(names.split(\",\")[1].split(\" \")[1])\n",
    "\n",
    "train[\"Greeting\"] = titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:1472: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n"
     ]
    }
   ],
   "source": [
    "X_train = train.loc[:, [\"Age\",\"Sex\",\"Fare\",\"Pclass\",\"Greeting\"]]\n",
    "X_test = test.loc[:, [\"Age\",\"Sex\",\"Fare\",\"Pclass\",\"Greeting\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Sex', 'Fare', 'Pclass', 'Greeting'], dtype='object')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.get_dummies(X_train, columns = [\"Sex\",\"Pclass\" ,\"Greeting\"], drop_first = True)\n",
    "X_test = pd.get_dummies(X_test, columns = [\"Sex\",\"Pclass\",\"Greeting\"], drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Fare', 'Sex_male', 'Pclass_2', 'Pclass_3', 'Greeting_Col.',\n",
       "       'Greeting_Don.', 'Greeting_Dr.', 'Greeting_Jonkheer.', 'Greeting_Lady.',\n",
       "       'Greeting_Major.', 'Greeting_Master.', 'Greeting_Miss.',\n",
       "       'Greeting_Mlle.', 'Greeting_Mme.', 'Greeting_Mr.', 'Greeting_Mrs.',\n",
       "       'Greeting_Ms.', 'Greeting_Rev.', 'Greeting_Sir.', 'Greeting_the'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
       "       n_estimators=100, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
       "       subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
      "       n_estimators=100, n_jobs=1, nthread=None,\n",
      "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
      "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
      "       subsample=1, verbosity=1)\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test)\n",
    "\n",
    "xg_predictions = pd.DataFrame({\n",
    "    \"PassengerID\":test.PassengerId,\n",
    "    \"Survived\":preds\n",
    "})\n",
    "\n",
    "xg_predictions.to_csv(\"/Users/theodoreplotkin/desktop/postmalone/GA_Data_Science/GA_github_repo/Untitled Folder/submissions2.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#very useful way to make comparisons between different models\n",
    "#sets up a graph of options to try out, according to different parameters you specify \n",
    "\n",
    "#define parameters you want to test\n",
    "#load them into a grid\n",
    "#fit (this can take awhile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"penalty\":[\"l1\",\"l2\"],\n",
    "    \"C\":[.0001,.001,.01,.1,1,10,100,1000,10000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-931765772341>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "#X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator = logreg, param_grid = param_grid , cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ['l1', 'l2'], 'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.01, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split5_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split6_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split7_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split8_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split9_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "grid_results = pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>split5_train_score</th>\n",
       "      <th>split6_train_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001714</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.0001, 'penalty': 'l1'}</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>...</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.616438</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.000317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001785</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.0001, 'penalty': 'l2'}</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>...</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.616438</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.000317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001942</td>\n",
       "      <td>0.000825</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l1'}</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>...</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.616438</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.000317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001707</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l2'}</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>...</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.616438</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.000317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001882</td>\n",
       "      <td>0.000858</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.01, 'penalty': 'l1'}</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>...</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.61596</td>\n",
       "      <td>0.616438</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.000317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       0.001714      0.000401         0.000376        0.000053  0.0001   \n",
       "1       0.001785      0.000198         0.000339        0.000040  0.0001   \n",
       "2       0.001942      0.000825         0.000409        0.000159   0.001   \n",
       "3       0.001707      0.000282         0.000296        0.000034   0.001   \n",
       "4       0.001882      0.000858         0.000377        0.000205    0.01   \n",
       "\n",
       "  param_penalty                          params  split0_test_score  \\\n",
       "0            l1  {'C': 0.0001, 'penalty': 'l1'}           0.611111   \n",
       "1            l2  {'C': 0.0001, 'penalty': 'l2'}           0.611111   \n",
       "2            l1   {'C': 0.001, 'penalty': 'l1'}           0.611111   \n",
       "3            l2   {'C': 0.001, 'penalty': 'l2'}           0.611111   \n",
       "4            l1    {'C': 0.01, 'penalty': 'l1'}           0.611111   \n",
       "\n",
       "   split1_test_score  split2_test_score       ...         split2_train_score  \\\n",
       "0           0.611111           0.617978       ...                    0.61596   \n",
       "1           0.611111           0.617978       ...                    0.61596   \n",
       "2           0.611111           0.617978       ...                    0.61596   \n",
       "3           0.611111           0.617978       ...                    0.61596   \n",
       "4           0.611111           0.617978       ...                    0.61596   \n",
       "\n",
       "   split3_train_score  split4_train_score  split5_train_score  \\\n",
       "0             0.61596             0.61596             0.61596   \n",
       "1             0.61596             0.61596             0.61596   \n",
       "2             0.61596             0.61596             0.61596   \n",
       "3             0.61596             0.61596             0.61596   \n",
       "4             0.61596             0.61596             0.61596   \n",
       "\n",
       "   split6_train_score  split7_train_score  split8_train_score  \\\n",
       "0             0.61596             0.61596             0.61596   \n",
       "1             0.61596             0.61596             0.61596   \n",
       "2             0.61596             0.61596             0.61596   \n",
       "3             0.61596             0.61596             0.61596   \n",
       "4             0.61596             0.61596             0.61596   \n",
       "\n",
       "   split9_train_score  mean_train_score  std_train_score  \n",
       "0            0.616438          0.616162         0.000317  \n",
       "1            0.616438          0.616162         0.000317  \n",
       "2            0.616438          0.616162         0.000317  \n",
       "3            0.616438          0.616162         0.000317  \n",
       "4            0.616438          0.616162         0.000317  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time',\n",
       "       'param_C', 'param_penalty', 'params', 'split0_test_score',\n",
       "       'split1_test_score', 'split2_test_score', 'split3_test_score',\n",
       "       'split4_test_score', 'split5_test_score', 'split6_test_score',\n",
       "       'split7_test_score', 'split8_test_score', 'split9_test_score',\n",
       "       'mean_test_score', 'std_test_score', 'rank_test_score',\n",
       "       'split0_train_score', 'split1_train_score', 'split2_train_score',\n",
       "       'split3_train_score', 'split4_train_score', 'split5_train_score',\n",
       "       'split6_train_score', 'split7_train_score', 'split8_train_score',\n",
       "       'split9_train_score', 'mean_train_score', 'std_train_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:1472: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n"
     ]
    }
   ],
   "source": [
    "cols = [\"param_C\", \"param_penalty\", \"mean_test_score\", \"std_test_score\",\n",
    "       \"rank_test_score\", \"mean_train_score\", \"std_train_score\"]\n",
    "grid_results = grid_results.loc[:, cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid_results.sort_values(by = \"rank_best_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
